{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4054427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Columns:  (3795, 11)\n",
      "Duplicate?: True\n",
      "Any missing values? False\n",
      "Rows and Columns after cleaning: (3795, 2)\n",
      "Duplicate? after cleaning: False\n",
      "Any missing values? False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('data/fakeNews.csv')\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "\n",
    "#drop unwanted columns\n",
    "df = df.drop([\"Date Posted\", \"Link\", \"Region\",\"Country\",\"Explanation\",\"Origin\",\"Origin_URL\",\"Fact_checked_by\",\"Poynter_Label\"], axis=1)\n",
    "print(\"Rows and Columns after cleaning:\", df.shape)\n",
    "\n",
    "# Create translation table once\n",
    "killpunctuation = str.maketrans('', '', string.punctuation + \"‘’“”\")\n",
    "\n",
    "#clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower() #convert to lower case\n",
    "    text = re.sub(r\"(@\\S+|https?\\S+|#\\S+)\", \"\", text) # remove @s, hashtags, URLS\n",
    "    text = text.translate(killpunctuation)   # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "   \n",
    "# Apply cleaning to 'text' column\n",
    "df[\"Text\"] = df[\"Text\"].apply(clean_text)\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={'Text': 'text', 'Binary Label': 'fake'})\n",
    "\n",
    "df[\"fake\"] = 1 # change classifcation of fake to 1\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "#save cleaned data\n",
    "df.to_csv('data/fakeNews_CLEAN.csv', index=False)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate? after cleaning:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d10f7ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Columns:  (3793, 7)\n",
      "Duplicate?: False\n",
      "Any missing values? False\n",
      "Date Posted    object\n",
      "Link           object\n",
      "Text           object\n",
      "Region         object\n",
      "Username       object\n",
      "Publisher      object\n",
      "Label           int64\n",
      "dtype: object\n",
      "Rows and Columns after cleaning: (3793, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/trueNews.csv')\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "#drop unwanted columns\n",
    "df = df.drop([\"Date Posted\",\"Link\",\"Region\",\"Username\",\"Publisher\"], axis=1)\n",
    "print(\"Rows and Columns after cleaning:\", df.shape)\n",
    "\n",
    "# Create translation table once\n",
    "killpunctuation = str.maketrans('', '', string.punctuation + \"‘’“”\")\n",
    "\n",
    "#clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower() #convert to lower case\n",
    "    text = re.sub(r\"(@\\S+|https?\\S+|#\\S+)\", \"\", text) # remove @s, hashtags, URLS\n",
    "    text = re.sub(r\"\\b(pictwitter\\S*|pic\\S*)\\b\", \"\", text) #remove pic twitter \n",
    "    text = text.translate(killpunctuation)   # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "   \n",
    "# Apply cleaning to 'text' column\n",
    "df[\"Text\"] = df[\"Text\"].apply(clean_text)\n",
    "\n",
    "#rename columns\n",
    "df = df.rename(columns={'Text': 'text', 'Label': 'fake'})\n",
    "\n",
    "df[\"fake\"] = 0 # change classifcation of fake to 1, real = 0\n",
    "\n",
    "#save cleaned data\n",
    "df.to_csv('data/trueNews_CLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6923415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Columns:  (2140, 3)\n",
      "Duplicate?: False\n",
      "Any missing values? False\n",
      "id        int64\n",
      "tweet    object\n",
      "label    object\n",
      "dtype: object\n",
      "Rows and Columns:  (2140, 2)\n",
      "Duplicate?: True\n",
      "Any missing values? False\n",
      "text    object\n",
      "fake     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('data/usable/covid19_Constraint_Val.csv')\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Create translation table once\n",
    "killpunctuation = str.maketrans('', '', string.punctuation + \"‘’“”\")\n",
    "\n",
    "\n",
    "def remove_emoji(txt): #remove emoji function from: https://appdividend.com/remove-emoji-from-the-text-in-python/\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower() #convert to lower case\n",
    "    text = re.sub(r\"(@\\S+|https?\\S+|#\\S+)\", \"\", text) # remove @s, hashtags, URLS\n",
    "    text = text.translate(killpunctuation)   # remove punctuation\n",
    "    text = remove_emoji(text)  # remove emojis\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "   \n",
    "# Apply cleaning to 'tweet' column\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean_tweet)\n",
    "\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "\n",
    "\n",
    "#convert label to binary\n",
    "df[\"fake\"] = df[\"label\"].map({\"fake\": 1, \"real\": 0})\n",
    "df = df.drop(\"label\", axis=1)\n",
    "\n",
    "df = df.drop(\"id\", axis=1) #drop id column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save cleaned data\n",
    "df.to_csv('data/usable/covid19_Constraint_Val_CLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f155d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Columns:  (2140, 3)\n",
      "Duplicate?: False\n",
      "Any missing values? False\n",
      "id        int64\n",
      "tweet    object\n",
      "label    object\n",
      "dtype: object\n",
      "Rows and Columns:  (2140, 2)\n",
      "Duplicate?: True\n",
      "Any missing values? False\n",
      "text    object\n",
      "fake     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/usable/covid19_english_test_with_labels.csv')\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# Create translation table once\n",
    "killpunctuation = str.maketrans('', '', string.punctuation + \"‘’“”\")\n",
    "\n",
    "\n",
    "def remove_emoji(txt): #remove emoji function from: https://appdividend.com/remove-emoji-from-the-text-in-python/\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower() #convert to lower case\n",
    "    text = re.sub(r\"(@\\S+|https?\\S+|#\\S+)\", \"\", text) # remove @s, hashtags, URLS\n",
    "    text = text.translate(killpunctuation)   # remove punctuation\n",
    "    text = remove_emoji(text)  # remove emojis\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "   \n",
    "# Apply cleaning to 'tweet' column\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean_tweet)\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "\n",
    "\n",
    "#convert label to binary\n",
    "df[\"fake\"] = df[\"label\"].map({\"fake\": 1, \"real\": 0})\n",
    "df = df.drop(\"label\", axis=1)\n",
    "\n",
    "df = df.drop(\"id\", axis=1) #drop id column\n",
    "\n",
    "\n",
    "\n",
    "#save cleaned data\n",
    "df.to_csv('data/usable/covid19_english_test_with_labels_CLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12d45b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and Columns:  (6424, 3)\n",
      "Duplicate?: False\n",
      "Any missing values? False\n",
      "id        int64\n",
      "tweet    object\n",
      "label    object\n",
      "dtype: object\n",
      "Rows and Columns:  (6424, 2)\n",
      "Duplicate?: True\n",
      "Any missing values? False\n",
      "text    object\n",
      "fake     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/usable/covid19labeldataset.csv')\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "\n",
    "# Create translation table once\n",
    "killpunctuation = str.maketrans('', '', string.punctuation + \"‘’“”\")\n",
    "\n",
    "\n",
    "def remove_emoji(txt): #remove emoji function from: https://appdividend.com/remove-emoji-from-the-text-in-python/\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', txt)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower() #convert to lower case\n",
    "    text = re.sub(r\"(@\\S+|https?\\S+|#\\S+)\", \"\", text) # remove @s, hashtags, URLS\n",
    "    text = text.translate(killpunctuation)   # remove punctuation\n",
    "    text = remove_emoji(text)  # remove emojis\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "   \n",
    "# Apply cleaning to 'tweet' column\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean_tweet)\n",
    "df = df.rename(columns={'tweet': 'text'})\n",
    "\n",
    "#convert label to binary\n",
    "df[\"fake\"] = df[\"label\"].map({\"fake\": 1, \"real\": 0})\n",
    "df = df.drop(\"label\", axis=1)\n",
    "\n",
    "df = df.drop(\"id\", axis=1) #drop id column\n",
    "\n",
    "\n",
    "\n",
    "#save cleaned data\n",
    "df.to_csv('data/usable/covid19labeldataset_CLEAN.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Rows and Columns: \", df.shape)\n",
    "\n",
    "#check duplicates\n",
    "print(\"Duplicate?:\" , df.duplicated().any())\n",
    "\n",
    "#check missing values\n",
    "has_missing = df.isna().any().any()\n",
    "print(\"Any missing values?\", has_missing)\n",
    "\n",
    "#check data types\n",
    "print(df.dtypes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
